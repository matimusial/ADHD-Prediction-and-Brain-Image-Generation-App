<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Specification - ADHD Prediction and Brain Image Generation App</title>
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <img src="../resources/logo.png" alt="Logo" class="logo">
    <h1>ADHD Prediction and Brain Image Generation App</h1>
    <nav>
        <a href="../index.html" class="tablink">Overview</a>
        <a href="instructions.html" class="tablink">Instructions</a>
        <a href="specification.html" class="tablink active">Specification</a>
        <a href="click-the-red-dot.html" class="tablink">Click the Brain</a>
        <a href="pong.html" class="tablink">Brain pong</a>
        <a href="tic-tac-toe.html" class="tablink">Tic Tac Brain</a>
    </nav>

    <div id="specification" class="content">
        <h2>Specification</h2>
        <h3>Data Analysis for Training CNN with EEG Data</h3>
        <ol>
            <li><strong>Data Loading and Filtering:</strong> EEG data is processed with a Butterworth bandpass filter with a lower frequency of 4 Hz and an upper frequency of 30 Hz.</li>
            <li><strong>Data Clipping:</strong> After filtering, the data is clipped to the 99.8th percentile, removing the extreme 0.2% of data.</li>
            <li><strong>Data Normalization:</strong> Data is normalized to the range [-1;1].</li>
            <li><strong>Data Transformation:</strong> Data is transformed into images of fixed size (frame size), labeled, shuffled, and fed into the neural network in the shape (number of images, number of channels, frame size, 1).</li>
        </ol>
        <h3>CNN Architecture for EEG Training</h3>
        <p><strong>Training Method:</strong></p>
        <ul>
            <li>Optimization algorithm: Adam.</li>
            <li>Loss function: binary_crossentropy.</li>
            <li>Callback ReduceLROnPlateau monitors validation loss (val_loss) and reduces the learning rate by half if the loss does not improve for 2 epochs (minimum rate: 0.0001).</li>
        </ul>
        <p><strong>Input Shape:</strong></p>
        <ul>
            <li>(number of channels, frame size, 1).</li>
        </ul>
        <h3>CNN Model</h3>
        <ol>
            <li><strong>First Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 16.</li>
                    <li>Kernel size: (10, 1).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>BatchNormalization: Data optimization.</li>
                    <li>Description: Feature extraction from EEG data.</li>
                </ul>
            </li>
            <li><strong>Average Pooling:</strong>
                <ul>
                    <li>Layer: AveragePooling2D.</li>
                    <li>Pool size: (2, 1).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Second Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 32.</li>
                    <li>Kernel size: (8, 1).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>BatchNormalization: Data optimization.</li>
                    <li>Description: Extraction of more complex features from EEG data.</li>
                </ul>
            </li>
            <li><strong>Average Pooling:</strong>
                <ul>
                    <li>Layer: AveragePooling2D.</li>
                    <li>Pool size: (2, 1).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Third Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 64.</li>
                    <li>Kernel size: (4, 1).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>BatchNormalization: Data optimization.</li>
                    <li>Description: Extraction of even more complex features from EEG data.</li>
                </ul>
            </li>
            <li><strong>Average Pooling:</strong>
                <ul>
                    <li>Layer: AveragePooling2D.</li>
                    <li>Pool size: (2, 1).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Flattening:</strong>
                <ul>
                    <li>Layer: Flatten.</li>
                    <li>Description: Transforming 2D data to 1D to enter the dense layer.</li>
                </ul>
            </li>
            <li><strong>Dropout:</strong>
                <ul>
                    <li>Layer: Dropout.</li>
                    <li>Parameters: rate=0.5.</li>
                    <li>Description: Regularizing the model by dropping 50% of neurons during training to prevent overfitting.</li>
                </ul>
            </li>
            <li><strong>First Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 64.</li>
                    <li>Activation: 'relu'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>Description: Full connection learning complex relationships in the data.</li>
                </ul>
            </li>
            <li><strong>Dropout:</strong>
                <ul>
                    <li>Layer: Dropout.</li>
                    <li>Parameters: rate=0.5.</li>
                    <li>Description: Regularizing the model by dropping 50% of neurons during training to prevent overfitting.</li>
                </ul>
            </li>
            <li><strong>Output Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 1.</li>
                    <li>Activation: 'sigmoid'.</li>
                    <li>Description: Final layer that produces binary output (classification probability).</li>
                </ul>
            </li>
        </ol>
        <h3>Data Analysis for Training CNN with MRI Data</h3>
        <ol>
            <li><strong>Data Loading:</strong> Data with image size 128x120.</li>
            <li><strong>Data Clipping:</strong> Clipping by 4 pixels top-bottom, checking if the image is square.</li>
            <li><strong>Data Normalization:</strong> Normalizing to the range [-1;1].</li>
            <li><strong>Data Transformation:</strong> Data is labeled and fed into training as (number of images, 120, 120, 1).</li>
        </ol>
        <h3>Training CNN for MRI Data</h3>
        <p><strong>Training Method:</strong></p>
        <ul>
            <li>Optimization algorithm: Adam.</li>
            <li>Loss function: binary_crossentropy.</li>
            <li>Callback ReduceLROnPlateau monitors validation loss (val_loss) and reduces the learning rate by half if the loss does not improve for 2 epochs (minimum rate: 0.0001).</li>
        </ul>
        <p><strong>Input Shape:</strong></p>
        <ul>
            <li>(120, 120, 1).</li>
        </ul>
        <h3>CNN Model</h3>
        <ol>
            <li><strong>First Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 32.</li>
                    <li>Kernel size: (3, 3).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Description: Extraction of basic features from input data.</li>
                </ul>
            </li>
            <li><strong>First Max Pooling:</strong>
                <ul>
                    <li>Layer: MaxPooling2D.</li>
                    <li>Pool size: (2, 2).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Second Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 64.</li>
                    <li>Kernel size: (3, 3).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Description: Extraction of more complex features from data.</li>
                </ul>
            </li>
            <li><strong>Second Max Pooling:</strong>
                <ul>
                    <li>Layer: MaxPooling2D.</li>
                    <li>Pool size: (2, 2).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Third Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 128.</li>
                    <li>Kernel size: (3, 3).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Description: Extraction of even more complex features from data.</li>
                </ul>
            </li>
            <li><strong>Third Max Pooling:</strong>
                <ul>
                    <li>Layer: MaxPooling2D.</li>
                    <li>Pool size: (2, 2).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Flattening:</strong>
                <ul>
                    <li>Layer: Flatten.</li>
                    <li>Description: Transforming 2D data to 1D to enter the dense layer.</li>
                </ul>
            </li>
            <li><strong>First Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 128.</li>
                    <li>Activation: 'relu'.</li>
                    <li>Description: Full connection learning complex relationships in the data.</li>
                </ul>
            </li>
            <li><strong>Dropout:</strong>
                <ul>
                    <li>Layer: Dropout.</li>
                    <li>Parameters: rate=0.5.</li>
                    <li>Description: Regularizing the model by dropping 50% of neurons during training to prevent overfitting.</li>
                </ul>
            </li>
            <li><strong>Output Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 1.</li>
                    <li>Activation: 'sigmoid'.</li>
                    <li>Description: Final layer that produces binary output (classification probability).</li>
                </ul>
            </li>
        </ol>
        <h3>Prediction for CNN Models for EEG and MRI</h3>
        <p><strong>Data Processing:</strong></p>
        <ul>
            <li>Data processed the same way as before training.</li>
            <li>The model returns a binary probability for each frame.</li>
            <li>The mean of the frames is calculated:
                <ul>
                    <li>If the mean exceeds the threshold of 0.5, the result is ADHD, and the mean * 100% is displayed.</li>
                    <li>If the result is healthy, (1 - mean) * 100% is displayed.</li>
                </ul>
            </li>
        </ul>
        <h3>Building and Training GAN Model</h3>
        <ol>
            <li><strong>Building the Generative Model:</strong>
                <ul>
                    <li>Model: Sequential.</li>
                    <li>Layers:
                        <ul>
                            <li>Dense: 256 units, LeakyReLU with slope 0.2, BatchNormalization.</li>
                            <li>Dense: 512 units, LeakyReLU with slope 0.2, BatchNormalization.</li>
                            <li>Dense: 1024 units, LeakyReLU with slope 0.2, BatchNormalization.</li>
                            <li>Dense: 120 * 120 * 1, activation 'tanh', Reshape to shape (120,120,1).</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><strong>Building the Discriminator Model:</strong>
                <ul>
                    <li>Model: Sequential.</li>
                    <li>Layers:
                        <ul>
                            <li>Input: Input shape (120, 120, 1).</li>
                            <li>Flatten.</li>
                            <li>Dense: 512 units, LeakyReLU with slope 0.2, Dropout 0.3.</li>
                            <li>Dense: 256 units, LeakyReLU with slope 0.2, Dropout 0.3.</li>
                            <li>Dense: 1, activation 'sigmoid'.</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><strong>Training the GAN Model:</strong>
                <ul>
                    <li>Gradient Tape: Using two tf.GradientTape objects to record operations for calculating gradients for the generator and discriminator.</li>
                    <li>Generating images: Generating fake images using the generator.</li>
                    <li>Passing through the discriminator:
                        <ul>
                            <li>Passing real images through the discriminator.</li>
                            <li>Passing generated images through the discriminator.</li>
                        </ul>
                    </li>
                    <li>Calculating losses:
                        <ul>
                            <li>Loss for the generator: g_loss calculated as the error of classifying fake images as real.</li>
                        </ul>
                    </li>
                    <li>Calculating gradients:
                        <ul>
                            <li>Gradients for the discriminator.</li>
                            <li>Gradients for the generator.</li>
                        </ul>
                    </li>
                    <li>Updating weights:
                        <ul>
                            <li>Applying gradients to optimizers to update weights of the discriminator and generator.</li>
                        </ul>
                    </li>
                </ul>
            </li>
        </ol>
        <h3>Database Specification</h3>
        <p><strong>Tables:</strong></p>
        <ul>
            <li><strong>models:</strong>
                <ul>
                    <li><strong>id:</strong> INT, PRIMARY KEY, AUTO_INCREMENT - Unique identifier for the model.</li>
                    <li><strong>name:</strong> VARCHAR(255) - Name (cnn_accuracy/gen_loss) of the model.</li>
                    <li><strong>channels:</strong> INT, NULL - Number of channels or NULL.</li>
                    <li><strong>input_shape:</strong> VARCHAR(255) - Input shape of the model as a tuple converted to string.</li>
                    <li><strong>type:</strong> VARCHAR(50) - Type of the model, allowed values: ['cnn_mri', 'cnn_eeg', 'gan_adhd', 'gan_control'].</li>
                    <li><strong>fs:</strong> FLOAT, NULL - Sampling frequency or NULL.</li>
                    <li><strong>plane:</strong> CHAR(1), NULL - Plane of the model, allowed values: ['A', 'S', 'C'] or NULL. (Axial/Sagittal/Coronal)</li>
                    <li><strong>description:</strong> VARCHAR(255) - Description of the model (learning rate, batch size, epochs); etc</li>
                </ul>
            </li>
            <li><strong>files:</strong>
                <ul>
                    <li><strong>id:</strong> INT, PRIMARY KEY, AUTO_INCREMENT - Unique identifier for the file.</li>
                    <li><strong>model_id:</strong> INT, FOREIGN KEY - References the id in the models table.</li>
                    <li><strong>file:</strong> LONGBLOB - Binary data of the model file.</li>
                </ul>
            </li>
        </ul>
        <p><strong>Relationships:</strong></p>
        <ul>
            <li>The <strong>files</strong> table has a foreign key relationship with the <strong>models</strong> table. The <strong>model_id</strong> in the <strong>files</strong> table references the <strong>id</strong> in the <strong>models</strong> table, establishing a one-to-one relationship where one model can have only one associated file.</li>
        </ul>
    </div>
</body>
</html>



